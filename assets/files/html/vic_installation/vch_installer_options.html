<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>Virtual Container Host Deployment Options | VMware vSphere Integrated Containers Engine Installation, version 0.7.0</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="gitbook/style.css">
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="./vch_installer_examples.html" />
    
    
    <link rel="prev" href="./install_vic_cli.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="2.1"
        data-chapter-title="Virtual Container Host Deployment Options"
        data-filepath="vch_installer_options.md"
        data-basepath="."
        data-revision="Wed Nov 09 2016 15:19:06 GMT+0100 (W. Europe Standard Time)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="./index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="introduction.html">
            
                
                    <a href="./introduction.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        Overview of vSphere Integrated Containers Engine for vSphere Administrators
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="contents_of_vic_binaries.html">
            
                
                    <a href="./contents_of_vic_binaries.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        Contents of the vSphere Integrated Containers Engine Binaries
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="vic_installation_prereqs.html">
            
                
                    <a href="./vic_installation_prereqs.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        Environment Prerequisites for vSphere Integrated Containers Engine Installation
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="networks.html">
            
                
                    <a href="./networks.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        Networks Used by vSphere Integrated Containers Engine
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="install_vic_cli.html">
            
                
                    <a href="./install_vic_cli.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        Deploy a Virtual Container Host
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="2.1" data-path="vch_installer_options.html">
            
                
                    <a href="./vch_installer_options.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        Virtual Container Host Deployment Options
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="vch_installer_examples.html">
            
                
                    <a href="./vch_installer_examples.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        Examples of Deploying a Virtual Container Host
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="verify_vch_deployment.html">
            
                
                    <a href="./verify_vch_deployment.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        Verify the Deployment of a Virtual Container Host
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="install_vic_plugin.html">
            
                
                    <a href="./install_vic_plugin.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        Installing the vSphere Web Client Plug-in for vSphere Integrated Containers Engine
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="plugin_vc_web.html">
            
                
                    <a href="./plugin_vc_web.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        Install the vSphere Integrated Containers Engine Plug-In on vCenter Server For Windows by Using a Web Server
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="plugin_vc_no_web.html">
            
                
                    <a href="./plugin_vc_no_web.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        Install the vSphere Integrated Containers Engine Plug-In on vCenter Server for Windows Without Access to a Web Server
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="plugin_vcsa_web.html">
            
                
                    <a href="./plugin_vcsa_web.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        Install the vSphere Integrated Containers Engine Plug-In on a vCenter Server Appliance by Using a Web Server
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="plugin_vcsa_no_web.html">
            
                
                    <a href="./plugin_vcsa_no_web.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        Install the vSphere Integrated Containers Engine Plug-In on a vCenter Server Appliance Without Access to a Web Server
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="plugin_verify_deployment.html">
            
                
                    <a href="./plugin_verify_deployment.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        Verify the Deployment of the vSphere Integrated Containers Engine Plug-In
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="troubleshoot_vic_install.html">
            
                
                    <a href="./troubleshoot_vic_install.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        Troubleshooting vSphere Integrated Containers Engine Installation
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="ts_resource_pool_error.html">
            
                
                    <a href="./ts_resource_pool_error.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        VCH Deployment Fails with Resource Pool Creation Error
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="ts_cli_argument_error.html">
            
                
                    <a href="./ts_cli_argument_error.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        VCH Deployment Fails with Unknown or Non-Specified Argument Error or Incorrect User Name Error
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="ts_firewall_error.html">
            
                
                    <a href="./ts_firewall_error.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        VCH Deployment Fails with Firewall Validation Error
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="ts_ui_not_appearing.html">
            
                
                    <a href="./ts_ui_not_appearing.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.4.</b>
                        
                        vSphere Integrated Containers Engine Plug-In Does Not Appear in the vSphere Web Client
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="ts_docker_version_error.html">
            
                
                    <a href="./ts_docker_version_error.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.5.</b>
                        
                        Docker Commands Fail with a Docker API Version Error
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="./" >VMware vSphere Integrated Containers Engine Installation, version 0.7.0</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="virtual-container-host-deployment-options">Virtual Container Host Deployment Options</h1>
<p>The command line utility for vSphere Integrated Containers Engine, <code>vic-machine</code>, provides a <code>create</code> command with options that allow you to customize the deployment of virtual container hosts to correspond to your vSphere environment.</p>
<ul>
<li><a href="#vsphere">vSphere Target Options</a></li>
<li><a href="#security">Security Options</a></li>
<li><a href="#datastore">Datastore Options</a></li>
<li><a href="#networking">Networking Options</a></li>
<li><a href="#deployment">Appliance Deployment Options</a></li>
</ul>
<p>To allow you to fine-tune the deployment of virtual container hosts, <code>vic-machine create</code> provides <a href="#advanced">Advanced Options</a>.</p>
<ul>
<li><a href="#adv-security">Advanced Security Options</a></li>
<li><a href="#static-ip">Options for Specifying a Static IP Address for the Virtual Container Host Endpoint VM</a></li>
<li><a href="#adv-container-net">Options for Configuring a Non-DHCP Network for Container Traffic</a></li>
<li><a href="#proxy">Options to Configure Virtual Container Hosts to Use Proxy Servers</a></li>
<li><a href="#adv-mgmt">Advanced Resource Management Options</a></li>
<li><a href="#adv-other">Other Advanced Options</a></li>
</ul>
<p><a name="vsphere"></a></p>
<h2 id="vsphere-target-options">vSphere Target Options</h2>
<p>The <code>create</code> command of the <code>vic-machine</code> utility requires you to provide information about where in your vSphere environment to deploy the virtual container host and the vCenter Server or ESXi user account to use.</p>
<h3 id="target"><code>--target</code></h3>
<p>Short name: <code>-t</code></p>
<p>The IPv4 address, fully qualified domain name (FQDN), or URL of the ESXi host or vCenter Server instance on which you are deploying a virtual container host. This option is always <strong>mandatory</strong>.</p>
<p>To facilitate IP address changes in your infrastructure, provide an FQDN whenever possible, rather than an IP address.</p>
<ul>
<li>If the target ESXi host is not managed by vCenter Server, provide the address of the ESXi host.<pre>--target <i>esxi_host_address</i></pre></li>
<li>If the target ESXi host is managed by vCenter Server, or if you are deploying to a cluster, provide the address of vCenter Server.<pre>--target <i>vcenter_server_address</i></pre></li>
<li><p>You can include the user name and password in the target URL. <pre>--target <i>vcenter_or_esxi_username</i>:<i>password</i>@<i>vcenter_or_esxi_address</i></pre></p>
<p>Wrap the user name or password in single quotes (Linux or Mac OS) or double quotes (Windows) if they include special characters.<pre>&apos;<i>vcenter_or_esxi_usern@me</i>&apos;:&apos;<i>p@ssword</i>&apos;@<i>vcenter_or_esxi_address</i></pre></p>
<p>If you do not include the user name in the target URL, you must specify the <code>user</code> option. If you do not specify the <code>password</code> option or include the password in the target URL, <code>vic-machine create</code> prompts you to enter the password.</p>
</li>
<li><p>If you are deploying a virtual container host on a vCenter Server instance that includes more than one datacenter, include the datacenter name in the target URL. If you include an invalid datacenter name, <code>vic-machine create</code> fails and suggests the available datacenters that you can specify. </p>
<pre>--target <i>vcenter_server_address</i>/<i>datacenter_name</i></pre>

<p>Wrap the datacenter name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces.</p>
<pre>--target <i>vcenter_server_address</i>/&apos;<i>datacenter name</i>&apos;</pre>

</li>
</ul>
<h3 id="user"><code>--user</code></h3>
<p>Short name: <code>-u</code></p>
<p>The username for the ESXi host or vCenter Server instance on which you are deploying a virtual container host.</p>
<p>If you are deploying a virtual container host on vCenter Server, specify a username for an account that has the Administrator role on that vCenter Server instance. </p>
<pre>--user <i>esxi_or_vcenter_server_username</i></pre>

<p>Wrap the user name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes special characters.</p>
<pre>--user &apos;<i>esxi_or_vcenter_server_usern@me</i>&apos;</pre>

<p>You can also specify the username in the URL that you pass to <code>vic-machine create</code> in the <code>target</code> option, in which case the <code>user</code> option is not required.</p>
<h3 id="password"><code>--password</code></h3>
<p>Short name: <code>-p</code></p>
<p>The password for the user account on the vCenter Server on which you  are deploying the virtual container host, or the password for the ESXi host if you are deploying directly to an ESXi host. If not specified, <code>vic-machine</code> prompts you to enter the password during deployment.</p>
<pre>--password <i>esxi_host_or_vcenter_server_password</i></pre>

<p>Wrap the password in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes special characters.</p>
<pre>--password &apos;<i>esxi_host_or_vcenter_server_p@ssword</i>&apos;</pre>

<p>You can also specify the username and password in the URL that you pass to <code>vic-machine create</code> in the <code>target</code> option, in which case the <code>password</code> option is not required.</p>
<h3 id="computeresource"><code>--compute-resource</code></h3>
<p>Short name: <code>-r</code></p>
<p>The relative path to the host, cluster, or resource pool in which to deploy the virtual container host. </p>
<p>If the vCenter Server instance on which you are deploying a virtual container host only includes a single instance of a standalone host or  cluster, <code>vic-machine create</code> automatically detects and uses those resources. If you are deploying to an ESXi host that has no resource pools, <code>vic-machine create</code> automatically uses the default resource pool. In these cases, you do not need to specify a compute resource when you run <code>vic-machine create</code>.</p>
<p>You specify the <code>compute-resource</code> option in the following circumstances:</p>
<ul>
<li>A vCenter Server instance includes multiple instances of standalone hosts or clusters, or a mixture of standalone hosts and clusters.</li>
<li>An ESXi host includes multiple resource pools. </li>
<li>You want to deploy the virtual container host to a specific resource pool in your environment. </li>
</ul>
<p>If you do not specify the <code>compute-resource</code> option and multiple possible resources exist, <code>vic-machine create</code> fails and suggests valid targets for <code>compute-resource</code> in the failure message. </p>
<ul>
<li>To deploy to a specific resource pool on an ESXi host, specify the name of the resource pool: <pre>--compute-resource  <i>resource_pool_name</i></pre></li>
<li>To deploy to a vCenter Server instance that has more than one standalone host that are not part of a cluster, specify the IPv4 address or fully qualified domain name (FQDN) of the target host:<pre>--compute-resource <i>host_address</i></pre></li>
<li>To deploy to a vCenter Server with more than one cluster, specify the name of the target cluster: <pre>--compute-resource <i>cluster_name</i></pre></li>
<li>To deploy to a specific resource pool on a standalone host that is managed by vCenter Server, specify the IPv4 address or FQDN of the target host and name of the resource pool:<pre>--compute-resource <i>host_name</i>/<i>resource_pool_name</i></pre></li>
<li>To deploy to a specific resource pool in a cluster, specify the names of the target cluster and the resource pool:<pre>--compute-resource <i>cluster_name</i>/<i>resource_pool_name</i></pre></li>
<li>Wrap the resource names in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if they include spaces:<pre>--compute-resource &apos;<i>cluster name</i>&apos;/&apos;<i>resource pool name</i>&apos;</pre></li>
</ul>
<p><a name="thumbprint"></a></p>
<h3 id="thumbprint"><code>--thumbprint</code></h3>
<p>Short name: None</p>
<p>The thumbprint of the vCenter Server or ESXi host certificate. Specify this option if your vSphere environment uses untrusted, self-signed certificates. If your vSphere environment uses trusted certificates that are signed by a known Certificate Authority (CA), you do not need to specify the <code>--thumbprint</code> option.</p>
<p><strong>NOTE</strong> If your vSphere environment uses untrusted, self-signed certificates, you can run <code>vic-machine create</code> without the <code>--thumbprint</code> option by using the <code>--force</code> option. However, running <code>vic-machine create</code> with the <code>--force</code> option rather than providing the certificate thumbprint is not recommended, because it permits man-in-the-middle attacks to go undetected.</p>
<p>To obtain the thumbprint of the vCenter Server or ESXi host certificate, run <code>vic-machine create</code> without the specifying the <code>--thumbprint</code> or <code>--force</code> options. The deployment of the virtual container host fails, but the resulting error message includes the required certificate thumbprint. You can copy the thumbprint from the error message and run vic-machine create again, including the <code>thumbprint</code> option.</p>
<pre>--thumbprint <i>certificate_thumbprint</i></pre>

<p><a name="security"></a></p>
<h2 id="security-options">Security Options</h2>
<p>When you deploy a virtual container host, you must specify the type of authentication to use when Docker clients connect to that virtual container host. 
&lt;!--</p>
<ul>
<li>Two-way authentication with trusted auto-generated TLS certificates that are signed by a Certificate Authority (CA). Specify the <a href="#tls-cname"><code>tls-cname</code></a> option when you deploy the virtual container host.</li>
<li>Server-side authentication with auto-generated, untrusted TLS certificates that are not signed by a CA, with no client-side verification. Specify the <a href="#no-tlsverify"><code>no-tlsverify</code></a> option when you deploy the virtual container host.</li>
<li>Authentication with trusted custom TLS certificates that are signed by a CA.  Specify the <a href="#cert"><code>cert</code></a> and <a href="#key"><code>key</code></a> advanced options when you deploy the virtual container host.</li>
<li>No TLS authentication. Any Docker client can connect to the virtual container host. Specify the <a href="#no-tls"><code>no-tls</code></a> advanced option when you deploy the virtual container host.</li>
</ul>
<p>For more information about the possible security configurations for virtual container hosts, see <a href="security.md">Securing Virtual Container Host Connections</a>.</p>
<p><strong>IMPORTANT</strong>: If you assign a static IP address to a virtual container host on the client network and you do not specify any authentication options, <code>vic-machine</code> behaves in the same way as if you set the <code>--tls-cname</code> option. If you do not set a static IP address on the virtual container host, it is <strong>mandatory</strong> to specify an authentication option when you deploy a virtual container host. For information about setting a static IP address on a virtual container host, see <a href="#static-ip">Options for Specifying a Static IP Address for the Virtual Container Host Endpoint VM</a> in Advanced Options.
--&gt;
The security options also allow you to configure virtual container hosts to connect to insecure registries and download container images by setting the <code>--insecure-registry</code> option.</p>
<p><a name="tls-cname"></a></p>
<h3 id="tlscname"><code>--tls-cname</code></h3>
<p>Short name: None</p>
<p>The Common Name to use in an auto-generated CA certificate if you require two-way, trusted TLS certificate authentication when connecting Docker clients to the virtual container host.</p>
<p>The <code>--tls-cname</code> option is the minimum option that you must specify when using auto-generated trusted TLS certificates. For information about further options that you can specify when using auto-generated trusted certificates, see  the descriptions of the <code>--tls-ca</code>, <code>--certificate-key-size</code>, and <code>--organization</code> options in <a href="#adv-security">Advanced Security Options</a>.</p>
<p>If you specify a static IP address for the virtual container host on the client network by setting the <code>--client-network-ip</code> and <code>--client-network-gateway</code> options, <code>vic-machine create</code> uses this address as the Common Name when it creates auto-generated trusted certificates. In this case, you do not need to specify <code>--tls-cname</code> or any other authentication options. For information about setting a static IP address on a virtual container host, see <a href="#static-ip">Options for Specifying a Static IP Address for the Virtual Container Host Endpoint VM</a> in Advanced Options.</p>
<p>When you specify the <code>--tls-cname</code> option, and potentially other options for auto-generating trusted TLS certificates, <code>vic-machine create</code> performs the following actions during the deployment of the virtual container host.</p>
<ul>
<li>Creates a folder with the same name as the virtual container host in the location in which you run <code>vic-machine create</code>.</li>
<li>Creates trusted CA, server, and client certificate/key pairs in the newly created folder:<ul>
<li><code>ca.pem</code></li>
<li><code>ca-key.pem</code></li>
<li><code>cert.pem</code></li>
<li><code>key.pem</code></li>
<li><code>server-cert.pem</code></li>
<li><code>server-key.pem</code></li>
</ul>
</li>
<li>Creates a browser-friendly PFX client certificate, <code>cert.pfx</code>, to use to authenticate connections to the VCH Admin portal for the virtual container host.</li>
</ul>
<p>Running <code>vic-machine create</code> with the <code>--tls-cname</code> option also creates an environment file named <code>vch_name.env</code>, that contains Docker environment variables that container developers can use to configure their Docker client environment:</p>
<ul>
<li>Activates TLS client verification.<pre>DOCKER_TLS_VERIFY=1</pre></li>
<li>The path to the client certificates.<pre>DOCKER_CERT_PATH=<i>path_to_certs</i></pre></li>
<li>The address of the virtual container host.<pre>DOCKER_HOST=<i>vch_address</i>:2376</pre></li>
</ul>
<p>You must provide copies of the certificate files and the environment file to container developers so that they can connect Docker clients to the virtual container host. </p>
<p>If you use trusted certificates, container developers run Docker commands with the <code>--tlsverify</code>, <code>--tlscacert</code>, <code>--tlscert</code>, and <code>--tlskey</code> options.</p>
<p>When you specify the <code>--tls-cname</code> option, you must provide an FQDN for the virtual container host or the name of the domain to which the virtual container host will belong. The system on which you run <code>vic-machine create</code> and the remote vCenter Server system must agree on the vCenter Server system&apos;s FQDN or domain. As a consequence, to use the <code>--tls-cname</code> option, you must have a DNS service running on the client network that the virtual container host uses. You cannot specify an IP address in the <code>--tls-cname</code> option. If you do not have a DNS service on the client network, you can still implement full TLS authentication with trusted certificates by either specifying a static IP address or by using the <code>--cert</code> and <code>--key</code> options to upload custom certificates.  </p>
<pre>--tls-cname vch-name.example.org</pre>
<pre>--tls-cname *.example.org</pre>

<p><a name="no-tlsverify"></a></p>
<h3 id="notlsverify"><code>--no-tlsverify</code></h3>
<p>Short name: <code>--kv</code></p>
<p>Authentication of the virtual container host with auto-generated TLS certificates that are not signed by a CA, with no client-side verification. The <code>vic-machine create</code> command still generates certificates, but these are untrusted, self-signed certificates. </p>
<p>If you configure the virtual container host for untrusted TLS certificate authentication, clients are not verified. Consequently, container developers do not require copies of the certificate and key files.</p>
<p>When you specify the <code>--no-tlsverify</code> option, <code>vic-machine create</code> performs the following actions during the deployment of the virtual container host.</p>
<ul>
<li>Creates a folder with the same name as the virtual container host in the location in which you run <code>vic-machine create</code>.</li>
<li>Creates an environment file named <code>vch_name.env</code>, that contains the <code>DOCKER_HOST=vch_address</code> environment variable, that you can provide to container developers to use to set up their Docker client environment.</li>
</ul>
<p>If you use untrusted certificates, container developers run Docker commands with the <code>--tls</code> option. The <code>--no-tlsverify</code> option takes no arguments. </p>
<pre>--no-tlsverify</pre>

<p><a name="registry"></a></p>
<h3 id="insecureregistry"><code>--insecure-registry</code></h3>
<p>Short name: <code>--dir</code></p>
<p>If your Docker environment stores Docker images in an insecure private registry server, you must configure virtual container hosts to connect to this private registry server when you deploy them. An insecure  private registry server is a private registry server that is secured by self-signed certificates rather than by TLS. You authorize connections from a virtual container host to an insecure private registry server by setting the URL of a registry server in the <code>insecure-registry</code> option. If the registry server listens on a specific port, add the port number to the URL.</p>
<p>You can specify <code>insecure-registry</code> multiple times to allow connections from the virtual container host to multiple insecure  private registry servers.</p>
<pre>--insecure-registry <i>registry_URL_1</i>
--insecure-registry <i>registry_URL_2</i>:<i>port_number</i>
</pre>

<p><strong>NOTE</strong>: The current builds of vSphere Integrated Containers do not yet support private registry servers that you secure by using TLS certificates.</p>
<p><a name="datastore"></a></p>
<h2 id="datastore-options">Datastore Options</h2>
<p>The <code>vic-machine</code> utility allows you to specify the datastore in which to store container image files, container VM files, and the files for the virtual container host appliance. You can also specify datastores in which to create container volumes. </p>
<ul>
<li>vSphere Integrated Containers Engine fully supports VMware vSAN datastores. </li>
<li>vSphere Integrated Containers Engine supports all alphanumeric characters, hyphens, and underscores in datastore paths and datastore names, but no other special characters.</li>
<li>If you specify different datastores in the different datastore options, and if no single host in a cluster can access all of those datastores, <code>vic-machine create</code> fails with an error.<pre>No single host can access all of the requested datastores. 
Installation cannot continue.</pre></li>
<li>If you specify different datastores in the different datastore options, and if only one host in a cluster can access all of them, <code>vic-machine create</code> succeeds with a warning.<pre>Only one host can access all of the image/container/volume datastores. 
This may be a point of contention/performance degradation and HA/DRS 
may not work as intended.</pre> </li>
</ul>
<p><a name="image"></a></p>
<h3 id="imagestore"><code>--image-store</code></h3>
<p>Short name: <code>-i</code></p>
<p>The datastore in which to store container image files, container VM files, and the files for the virtual container host appliance. The <code>--image-store</code> option is <strong>mandatory</strong> if there is more than one datastore in your vSphere environment. If there is only one datastore in your vSphere environment, the <code>--image-store</code> option is not required. </p>
<p>If you are deploying the virtual container host to a vCenter Server cluster, the datastore that you designate in the <code>image-store</code> option must be shared by at least two ESXi hosts in the cluster. Using non-shared datastores is possible, but limits the use of vSphere features such as vSphere vMotion&#xAE; and VMware vSphere Distributed Resource Scheduler&#x2122; (DRS).</p>
<p>When you deploy a virtual container host, <code>vic-machine</code> creates a set of folders in the target datastore: </p>
<ul>
<li>A folder with the same name as the virtual container host, at the top level of the datastore. This folder contains the VM files for the virtual container host appliance.</li>
<li>A folder named <code>VIC</code> inside the virtual container host folder. The <code>VIC</code> folder contains a folder that uses the UUID of the virtual container host endpoint VM as its name. The <code>VIC/vch_uuid</code> folder contains a subfolder named <code>images</code>, in which to store all of the container images that you pull into the virtual container host. </li>
</ul>
<p>You can specify a datastore folder to use as the image store in the format <code>datastore_name/path</code>. If the path to the folder that you specify does not already exist, <code>vic-machine create</code> creates it. In this case, <code>vic-machine</code> still creates the folder for the files of the virtual container host appliance at the top level of the datastore. However, <code>vic-machine create</code> creates the <code>VIC</code> folder inside the <code>datastore_name/path</code> folder, rather than in the same folder as the virtual container host files. </p>
<p>By specifying the path to a datastore folder in the <code>--image-store</code> option, you can designate the same datastore folder as the image store for multiple virtual container hosts. In this way, <code>vic-machine create</code> creates only one <code>VIC</code> folder in the datastore, at the path that you specify. The <code>VIC</code> folder contains one <code>vch_uuid/images</code> folder for each virtual container host that you deploy. By creating one <code>vch_uuid/images</code> folder for each virtual container host, vSphere Integrated Containers Engine limits the potential for conflicts of image use between virtual container hosts, even if you share the same image store folder between multiple hosts.</p>
<p><strong>NOTE</strong>: In the current builds of vSphere Integrated Containers Engine, sharing an image store folder between multiple virtual container hosts can lead to inconsistent behavior. Designate a different folder for the image store for each virtual container host, or omit the datastore folder from the <code>--image-store</code> option.</p>
<p>When container developers create containers, vSphere Integrated Containers Engine stores the files for container VMs at the top level of the image store, in folders that have the same name as the containers.</p>
<p>vSphere Integrated Containers Engine supports all alphanumeric characters, hyphens, and underscores in datastore paths and datastore names, but no other special characters. </p>
<ul>
<li>Specify a datastore as the image store:<pre>--image-store <i>datastore_name</i></pre> </li>
<li>Specify a datastore folder as the image store:<pre>--image-store <i>datastore_name</i>/<i>path</i></pre> </li>
<li>Wrap the datastore name and path in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if they include spaces:  <pre>--image-store &apos;<i>datastore name</i>&apos;/&apos;<i>datastore path</i>&apos;</pre> </li>
</ul>
<p>If you specify an invalid datastore name, <code>vic-machine create</code> fails and suggests valid datastores.</p>
<p><a name="volume-store"></a></p>
<h3 id="volumestore"><code>--volume-store</code></h3>
<p>Short name: <code>--vs</code></p>
<p>The datastore in which to create volumes when container developers use the <code>docker volume create</code> or <code>docker create -v</code> commands. When you specify the <code>volume-store</code> option, you  provide the name of the target datastore and a label for the volume store. You can optionally provide a path to a specific folder in the datastore in which to create the volume store. If the folders that you specify in the path do not already exist on the datastore, <code>vic-machine create</code> creates the appropriate folder structure. If you specify an invalid datastore name, <code>vic-machine create</code> fails and suggests valid datastores. </p>
<p><strong>IMPORTANT</strong>: If multiple virtual container hosts will use the same datastore for their volume stores, specify a different datastore folder for each virtual container host. Do not designate the same datastore folder as the volume store for multiple virtual container hosts.</p>
<p>If you are deploying the virtual container host to a vCenter Server cluster, the datastore that you designate in the <code>volume-store</code> option should be shared by at least two ESXi hosts in the cluster. Using non-shared datastores is possible and <code>vic-machine create</code> succeeds, but it issues a warning that this configuration limits the use of vSphere features such as vSphere vMotion and DRS.</p>
<p>The label that you specify is the volume store name that Docker uses. For example, the volume store label appears in the information for a virtual container host when container developers run <code>docker info</code>. Container developers specify the volume store label in the <code>docker volume create --opt VolumeStore=volume_store_label</code> option when they create a volume.</p>
<p><strong>IMPORTANT</strong> If you do not specify the <code>volume-store</code> option, no  volume store is created and container developers cannot use the <code>docker volume create</code> or <code>docker create -v</code> commands.</p>
<ul>
<li><p>If you only require one volume store, you can set the volume store label to <code>default</code>. If you set the volume store label to <code>default</code>, container developers do not need to specify the <code>--opt VolumeStore=volume_store_label</code> option when they run <code>docker volume create</code>. </p>
<p><strong>NOTE</strong>: If container developers intend to use <code>docker create -v</code> to create containers that are attached to anonymous or named volumes, you must create a volume store with a label of <code>default</code>.</p>
<pre>--volume-store <i>datastore_name</i>:default</pre>
</li>
<li><p>If you specify the target datastore and the volume store label, <code>vic-machine create</code> creates a folder named <code>VIC/volumes</code> at the top level of the target datastore. Any volumes that container developers create will appear in the <code>VIC/volumes</code> folder.</p>
<pre>--volume-store <i>datastore_name</i>:<i>volume_store_label</i></pre></li>
<li><p>If you specify the target datastore, a datastore path, and the volume store label, <code>vic-machine create</code> creates a folder named <code>volumes</code> in the location that you specify in the datastore path. Any volumes that container developers create will appear in the <code>path/volumes</code> folder.</p>
<pre>--volume-store <i>datastore_name</i>/<i>datastore_path</i>:<i>volume_store_label</i></pre></li>
<li><p>Wrap the datastore name and path in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if they include spaces. The volume store label cannot include spaces.</p>
<pre>--volume-store &apos;<i>datastore name</i>&apos;/&apos;<i>datastore path</i>&apos;:<i>volume_store_label</i></pre></li>
<li><p>You can specify the <code>volume-store</code> option multiple times, to create multiple volume stores for the virtual container host.</p>
<pre>--volume-store <i>datastore_name</i>/path:<i>volume_store_label_1</i>
--volume-store <i>datastore_name</i>/<i>path</i>:<i>volume_store_label_2</i>
[...]
--volume-store <i>datastore_name</i>/<i>path</i>:<i>volume_store_label_n</i>
</pre>

</li>
</ul>
<p><a name="networking"></a></p>
<h2 id="networking-options">Networking Options</h2>
<p>The <code>vic-machine create</code> utility allows you to specify different networks for the different types of traffic between containers, the virtual container host, the external internet, and your vSphere environment. For information about the different networks that virtual container hosts use, see <a href="networks.html">Networks Used by vSphere Integrated Containers Engine</a>.</p>
<p><strong>IMPORTANT</strong>: A virtual container host supports a maximum of 3 distinct networks. Because the bridge and container networks require  their own distributed port groups, at least two of the external, client, and management networks must share a network.</p>
<p>By default, <code>vic-machine create</code> obtains IP addresses for virtual container host endpoint VMs by using DHCP. For information about how to specify a static IP address for the virtual container host endpoint VM on the client, external, and management networks, see <a href="#static-ip">Specify a Static IP Address for the Virtual Container Host Endpoint VM</a> in Advanced Options.</p>
<p>If your network access is controlled by a proxy server, see <a href="#proxy">Options to Configure Virtual Container Hosts to Use Proxy Servers</a> in Advanced Options. </p>
<p><a name="bridge"></a></p>
<h3 id="bridgenetwork"><code>--bridge-network</code></h3>
<p>Short name: <code>-b</code></p>
<p>A distributed port group that container VMs use to communicate with each other. </p>
<p>The <code>bridge-network</code> option is <strong>mandatory</strong> if you are deploying a virtual container host to vCenter Server.</p>
<p>In a vCenter Server environment, before you run <code>vic-machine create</code>, you must create a distributed virtual switch and a distributed port group. You must add the target ESXi host or hosts to the distributed virtual switch, and assign a VLAN ID to the port group, to ensure that the bridge network is isolated. For information about how to create a distributed virtual switch and port group, see <em>Network Requirements</em> in <a href="vic_installation_prereqs.html#networkreqs">Environment Prerequisites for vSphere Integrated Containers Engine Installation</a>.</p>
<p>You pass the name of the distributed port group to the <code>bridge-network</code> option. Each virtual container host requires its own distributed port group. </p>
<p><strong>IMPORTANT</strong> </p>
<ul>
<li>Do not assign the same <code>bridge-network</code> distributed port group to multiple virtual container hosts. Sharing a distributed port group between virtual container hosts might result in multiple container VMs being assigned the same IP address. </li>
<li>Do not use the <code>bridge-network</code> distributed port group as the target for any of the other <code>vic-machine create</code> networking options.</li>
</ul>
<p>If you specify an invalid network name, <code>vic-machine create</code> fails and suggests valid networks.</p>
<p>The <code>bridge-network</code> option is <strong>optional</strong> when you are deploying a virtual container host to an ESXi host with no vCenter Server. In this case, if you do not specify <code>bridge-network</code>, <code>vic-machine</code> creates a  virtual switch and a port group that each have the same name as the virtual container host. You can optionally specify this option to assign an existing port group for use as the bridge network for container VMs. You can also optionally specify this option to create a new virtual switch and port group that have a different name to the virtual container host.</p>
<pre>--bridge-network <i>distributed_port_group_name</i></pre>

<p>Wrap the distributed port group name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces.</p>
<pre>--bridge-network &apos;<i>distributed port group name</i>&apos;</pre>

<p>For information about how to specify a range of IP addresses for additional bridge networks, see <a href="#bridge-range"><code>bridge-network-range</code></a> in Advanced Networking Options.</p>
<p><a name="client-network"></a></p>
<h3 id="clientnetwork"><code>--client-network</code></h3>
<p>Short name: <code>--cln</code></p>
<p>The network that the virtual container host uses to generate the Docker API. The Docker API only uses this network.</p>
<p>If not specified, the virtual container host uses the external network for client traffic. If you specify an invalid network name, <code>vic-machine create</code> fails and suggests valid networks.</p>
<pre>--client-network <i>network_name</i></pre>

<p>Wrap the network name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces.</p>
<pre>--client-network &apos;<i>network name</i>&apos;</pre>

<p><a name="external-network"></a></p>
<h3 id="externalnetwork"><code>--external-network</code></h3>
<p>Short name: <code>--en</code></p>
<p>The network for containers to use to connect to the Internet. Virtual container hosts use the external network to pull container images, for example from <a href="https://hub.docker.com/" target="_blank">https://hub.docker.com/</a>. Container VMs use the external network to publish network services. If you define the external network, you can deploy containers directly on the external interface. </p>
<p>If not specified, containers use the default VM Network for external traffic. If you specify an invalid network name, <code>vic-machine create</code> fails and suggests valid networks.</p>
<pre>--external-network <i>network_name</i></pre>

<p>Wrap the network name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces.</p>
<pre>--external-network &apos;<i>network name</i>&apos;</pre>

<p><a name="management-network"></a></p>
<h3 id="managementnetwork"><code>--management-network</code></h3>
<p>Short name: <code>--mn</code></p>
<p>The network that the virtual container host uses to communicate with vCenter Server and ESXi hosts. Container VMs use this network to communicate with the virtual container host. </p>
<p>If not specified, the virtual container host uses the external network for management traffic. If you specify an invalid network name, <code>vic-machine create</code> fails and suggests valid networks.</p>
<pre>--management-network <i>network_name</i></pre>

<p>Wrap the network name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces.</p>
<pre>--management-network &apos;<i>network name</i>&apos;</pre>

<p><a name="container-network"></a></p>
<h3 id="containernetwork"><code>--container-network</code></h3>
<p>Short name: <code>--cn</code></p>
<p>A network for container VMs to use for external communication when container developers  run <code>docker run</code> or <code>docker create</code> with the <code>--net</code> option. </p>
<p>To specify a container network, you provide the name of a distributed port group for the container VMs to use, and an optional descriptive name for the container network for use by Docker.  If you do not specify a descriptive name, Docker uses the vSphere network name. If you specify an invalid network name, <code>vic-machine create</code> fails and suggests valid networks.</p>
<ul>
<li>You can specify a vSphere network as the container network.</li>
<li>The distributed port group must exist before you run <code>vic-machine create</code>. </li>
<li>You cannot use the same distributed port group as you use for the bridge network. </li>
<li>You can create the distributed port group on the same distributed virtual switch as the distributed port group that you use for the bridge network.</li>
<li>If the network that you specify in the <code>container-network</code> option does not support DHCP, see <a href="#adv-container-net">Options for Configuring a Non-DHCP Network for Container Traffic</a> in Advanced Options. </li>
<li>The descriptive name appears under <code>Networks</code> when you run <code>docker info</code> on the deployed virtual container host.</li>
<li>Container developers use the descriptive name in the <code>--net</code> option when they run <code>docker run</code> or <code>docker create</code>.</li>
</ul>
<p>If you do not specify the <code>container-network</code> option, or if container developers run <code>docker run</code> or <code>docker create</code> without specifying <code>--net</code>, container VMs use the bridge network. </p>
<pre>--container-network <i>distributed_port_group_name</i>:<i>container_network_name</i></pre>

<p>Wrap the distributed port group name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces. The descriptive name cannot include spaces.</p>
<pre>--container-network &apos;<i>distributed port group name</i>&apos;:<i>container_network_name</i></pre>

<p><a name="deployment"></a></p>
<h2 id="appliance-deployment-options">Appliance Deployment Options</h2>
<p>The <code>vic-machine</code> utility provides options to customize the virtual container host appliance.</p>
<h3 id="name"><code>--name</code></h3>
<p>Short name: <code>-n</code></p>
<p>A name for the virtual container host appliance. If not specified, <code>vic-machine</code> sets the name of the virtual container host to <code>virtual-container-host</code>. If a virtual container host of the same name exists on the ESXi host or in the vCenter Server inventory, or if a folder of the same name exists in the target datastore, the deployment of the virtual container host fails.</p>
<pre>--name <i>vch_appliance_name</i></pre>

<p>Wrap the appliance name in single quotes (&apos;) on Mac OS and Linux and in double quotes (&quot;) on Windows if it includes spaces.</p>
<pre>--name &apos;<i>vch appliance name</i>&apos;</pre>

<h3 id="memory"><code>--memory</code></h3>
<p>Short name: <code>--mem</code></p>
<p>Limit the amount of memory that is available for use by the virtual container host appliance and container VMs. Specify the memory limit value in MB. If not specified, <code>vic-machine create</code> sets the limit to 0 (unlimited).</p>
<pre>--memory 1024</pre>

<h3 id="cpu"><code>--cpu</code></h3>
<p>Short name: None</p>
<p>Limit the amount of CPU capacity that is available for use by the virtual container host appliance and container VMs. Specify the CPU limit value in MHz. If not specified, <code>vic-machine create</code> sets the limit to 0 (unlimited).</p>
<pre>--cpu 1024</pre>

<h3 id="force"><code>--force</code></h3>
<p>Short name: <code>-f</code></p>
<p>Forces <code>vic-machine create</code> to ignore warnings and non-fatal errors and continue with the deployment of a virtual container host. Errors such as an incorrect compute resource still cause the installation to fail.</p>
<p>If your vSphere environment uses untrusted, self-signed certificates, you can use the <code>--force</code> option to deploy a virtual container host without providing the thumbprint of the vCenter Server or ESXi host in the <code>thumbprint</code> option. </p>
<p><strong>IMPORTANT</strong> Running <code>vic-machine create</code> with the <code>--force</code> option rather than providing the certificate thumbprint is not recommended, because it permits man-in-the-middle attacks to go undetected.</p>
<pre>--force</pre>

<h3 id="timeout"><code>--timeout</code></h3>
<p>Short name: none</p>
<p>The timeout period for uploading the vSphere Integrated Containers Engine  appliance and container images to the ESXi host, and for powering on the appliance. Specify a value in the format <code>XmYs</code> if the default timeout of 3m0s is insufficient.</p>
<pre>--timeout 5m0s</pre> 

<p><a name="advanced"></a></p>
<h1 id="advanced-options">Advanced Options</h1>
<p>The options in this section are exposed in the <code>vic-machine create</code> help if you run <code>vic-machine-darwin-linux-windows create --extended-help</code>, or <code>vic-machine-darwin-linux-windows create -x</code>. </p>
<p><a name="adv-security"></a></p>
<h2 id="advanced-security-options">Advanced Security Options</h2>
<p>The advanced security options allow you to customize the authentication of connections from Docker clients to virtual container hosts.</p>
<ul>
<li>Add optional information to auto-generated trusted TLS certificates by specifying the <code>--tls-ca</code>, <code>--certificate-key-size</code>, and <code>--organization</code> options.</li>
<li>Use custom trusted TLS certificates by using the <code>--cert</code> and <code>--key</code> options.</li>
<li>Disable TLS authentication completely by using the <code>--no-tls</code> option.</li>
</ul>
<h3 id="tlsca"><code>--tls-ca</code></h3>
<p>Short name: <code>--ca</code></p>
<p>Certificate Authority (CA) files to use to verify Docker client certificates. Specify the <code>--tls-ca</code> option if your certificates are validated by a CA that is not commonly recognized. Specify the <code>--tls-ca</code> option multiple times to specify multiple CA files. </p>
<pre>--tls-ca <i>path_to_ca_file</i></pre>

<h3 id="certificatekeysize"><code>--certificate-key-size</code></h3>
<p>Short name: <code>--ksz</code></p>
<p>The size of the key for <code>vic-machine create</code> to use when it creates auto-generated trusted certificates. If not specified, <code>vic-machine create</code> creates keys with default size of 2048 bits. It is not recommended to use key sizes of less than 2048 bits.</p>
<pre>--certificate-key-size 3072</pre>

<h3 id="organization"><code>--organization</code></h3>
<p>Short name: None</p>
<p>A list of identifiers to record in auto-generated trusted certificates. If not specified,<code>vic-machine create</code> uses the name of the virtual container host as the organization value. It also uses the IP address or FQND of the virtual container host as the organization if you set a static IP address by using the <code>--client-network-ip</code> and <code>--client-network-gateway</code> options.</p>
<pre>--organization <i>organization_name</i></pre>

<p><a name="cert"></a></p>
<h3 id="cert"><code>--cert</code></h3>
<p>Short name: none</p>
<p>The path to a custom X.509 certificate that has been signed by a CA, for the Docker API to use to authenticate the virtual container host with a Docker client.</p>
<ul>
<li>This option is mandatory if you use custom TLS certificates, rather than auto-generated certificates, to authenticate connections between Docker clients and the virtual container hosts.</li>
<li>Use this option in combination with the <code>key</code> option, that provides the path to the private key file for the custom certificate.</li>
<li>Include the names of the certificate and key files in the paths.</li>
<li>If you use trusted custom certificates, container developers run Docker commands with the <code>--tlsverify</code>, <code>--tlscacert</code>, <code>--tlscert</code>, and <code>--tlskey</code> options.</li>
</ul>
<pre>--cert <i>path_to_certificate_file</i>/<i>certificate_file_name</i>.pem 
--key <i>path_to_key_file</i>/<i>key_file_name</i>.pem
</pre> 

<p>Wrap the folder names in the paths in single quotes (Linux or Mac OS) or double quotes (Windows) if they include spaces.</p>
<pre>--cert &apos;<i>path to certificate file</i>&apos;/<i>certificate_file_name</i>.pem 
--key &apos;<i>path to key file</i>&apos;/<i>key_file_name</i>.pem
</pre> 

<p><a name="key"></a></p>
<h3 id="key"><code>--key</code></h3>
<p>Short name: none</p>
<p>The path to the private key file to use with a custom CA certificate. This option is mandatory if you specify the <code>cert</code> option, that provides the path to a custom X.509 certificate file. Include the names of the certificate and key files in the paths. </p>
<pre>--cert <i>path_to_certificate_file</i>/<i>certificate_file_name</i>.pem 
--key <i>path_to_key_file</i>/<i>key_file_name</i>.pem
</pre> 

<p>Wrap the folder names in the paths in single quotes (Linux or Mac OS) or double quotes (Windows) if they include spaces.</p>
<pre>--cert &apos;<i>path to certificate file</i>&apos;/<i>certificate_file_name</i>.pem 
--key &apos;<i>path to key file</i>&apos;/<i>key_file_name</i>.pem
</pre>

<p><a name="no-tls"></a></p>
<h3 id="notls"><code>--no-tls</code></h3>
<p>Short name: <code>-k</code></p>
<p>Disables TLS authentication of connections between the Docker client and  the virtual container host. </p>
<p>Set the <code>no-tls</code> option if you do not require TLS authentication between the virtual container host and the Docker client. Any Docker client can connect to the virtual container host if you disable TLS authentication. </p>
<p>If you use the <code>no-tls</code> option, container developers connect Docker clients to the virtual container host via port 2375, instead of via port 2376.</p>
<pre>--no-tls</pre>


<p><a name="static-ip"></a></p>
<h2 id="options-for-specifying-a-static-ip-address-for-the-virtual-container-host-endpoint-vm">Options for Specifying a Static IP Address for the Virtual Container Host Endpoint VM</h2>
<p>You can specify a static IP address for the virtual container host endpoint VM on each of the client, external, and management networks. DHCP is used for the endpoint VM for any network on which you do not specify a static IP address.</p>
<p>If you specify static IP addresses, you can only specify one static IP address on a given port group. If more than one of the client, external, or management networks shares a port group, you can only specify an IP address for one of those networks. The same address is then used for all of the networks that share that port group.</p>
<p>Assigning the same subnet to multiple port groups can cause routing problems.  If <code>vic-machine create</code> detects that you have assigned the same subnet to multiple port groups, it issues a warning.</p>
<p>To specify a static IP address for the endpoint VM, you provide an IP address, and a gateway address. You can also optionally specify one or more DNS server addresses.</p>
<p><strong>IMPORTANT</strong>: If you assign a static IP address to a virtual container host on the client network by setting the <code>--client-network-ip</code> and <code>--client-network-gateway</code> options, <code>vic-machine create</code> uses this address to auto-generate trusted CA certificates. In this case, two-way TLS authentication with trusted certificates is implemented by default, and you do not need to perform any additional TLS configuration when you deploy the virtual container host. If you assign a static IP to a virtual container host on the client network, <code>vic-machine create</code> creates the same certificate and environment variable files as described in the <a href="#tls-cname"><code>--tls-cname</code> option</a>.</p>
<h3 id="dnsserver"><code>--dns-server</code></h3>
<p>Short name: None</p>
<p>A DNS server to use if you specify static IP addresses for the virtual container host on the client, external, and management networks. You can specify <code>dns-server</code> multiple times, to configure multiple DNS servers.  </p>
<p>If you specify <code>dns-server</code> but you do not specify a static IP address for one or more of the client, external, and management networks, <code>vic-machine create</code> ignores the <code>dns-server</code> setting for that network and uses the DNS servers that are provided by DHCP. </p>
<p>If you use a mixture of static and DHCP addresses for the virtual container host on the different networks, the virtual container host uses the DNS servers that you specify in <code>dns-server</code> and those that DHCP provides.</p>
<p>If you specify static IP address for the virtual container host on any of the client, external, and management networks and you do not specify <code>dns-server</code>, the DNS server defaults to 8.8.8.8 and 8.8.4.4. </p>
<pre>--dns-server=172.16.10.10
--dns-server=172.16.10.11
</pre>

<h3 id="clientnetworkip-externalnetworkip-managementnetworkip"><code>--client-network-ip</code>, <code>--external-network-ip</code>, <code>--management-network-ip</code></h3>
<p>Short name: None</p>
<p>A static IP address for the virtual container host on the client, external, or management network. If you specify an IP address by using <code>client/external/management-network-ip</code>, you must also specify a  corresponding gateway address by using <code>client/external/management-network-gateway</code>. If you specify neither a gateway nor an IP address for a given network, <code>vic-machine create</code> uses DHCP to obtain an IP address for the virtual container host endpoint VM on that network.</p>
<p>You can specify IP addresses in CIDR format.</p>
<pre>--external-network-ip 192.168.X.N/24
--management-network-ip 192.168.Y.N/24
--client-network-ip 192.168.Z.N/24
</pre>

<p>You can also specify IP addresses as resolvable FQDNs. If you specify an FQDN, <code>vic-machine create</code> uses the netmask from the gateway.</p>
<pre>--external-network-ip=vch27-team-a.internal.domain.com
--management-network-ip=vch27-team-b.internal.domain.com
--client-network-ip=vch27-team-c.internal.domain.com
</pre>

<h3 id="clientnetworkgateway-externalnetworkgateway-managementnetworkgateway"><code>--client-network-gateway</code>, <code>--external-network-gateway</code>, <code>--management-network-gateway</code></h3>
<p>Short name: None</p>
<p>The gateway to use if you specify a static IP address for the virtual container host on the client, external, or management network. If you specify a gateway address by using <code>client/external/management-network-gateway</code>, you must also specify a corresponding IP address by using <code>client/external/management-network-ip</code>. If you specify neither a gateway nor an IP address for a given network, <code>vic-machine create</code> uses DHCP to obtain an IP address for the virtual container host endpoint VM on that network.</p>
<p>You specify gateway addresses in CIDR format.</p>
<pre>
--external-network-gateway 192.168.X.1/24
--management-network-gateway 192.168.Y.1/24
--client-network-gateway 192.168.Z.1/24
</pre>


<p><a name="adv-container-net"></a></p>
<h2 id="options-for-configuring-a-nondhcp-network-for-container-traffic">Options for Configuring a Non-DHCP Network for Container Traffic</h2>
<p>If the network that you specify in the <code>container-network</code> option does not support DHCP, you must specify the <code>container-network-gateway</code> option. You can optionally specify one or more DNS servers and a range of IP addresses for container VMs on the container network. </p>
<p>For information about the container network, see the section on the <a href="#container-network"><code>container-network</code> option</a>.</p>
<h3 id="containernetworkgateway"><code>--container-network-gateway</code></h3>
<p>Short name: <code>--cng</code></p>
<p>The gateway for the subnet of the container network. This option is required if the network that you specify in the <code>container-network</code> option does not support DHCP. Specify the gateway in the format <code>container_network:subnet</code>. If you specify this option, it is recommended that you also specify the  <code>container-network-dns</code> option.</p>
<p>When you specify the container network gateway, you must use the distributed port group that you specify in the <code>container-network</code> option. If you specify <code>container-network-gateway</code> but you do not specify <code>container-network</code>, or if you specify a different distributed port group to the one that you specify in <code>container-network</code>, <code>vic-machine create</code> fails with an error.</p>
<pre>--container-network-gateway <i>distributed_port_group_name</i>:<i>gateway_ip_address</i>/<i>subnet_mask</i></pre>

<p>Wrap the distributed port group name in single quotes (Linux or Mac OS) or double quotes (Windows) if it includes spaces.</p>
<pre>--container-network-gateway &apos;<i>distributed port group name</i>&apos;:<i>gateway_ip_address</i>/<i>subnet_mask</i></pre>

<h3 id="containernetworkdns"><code>--container-network-dns</code></h3>
<p>Short name: <code>--cnd</code></p>
<p>The address of the DNS server for the container network. This option is recommended if the network that you specify in the <code>container-network</code> option does not support DHCP. </p>
<p>When you specify the container network DNS server, you must use the distributed port group that you specify in the <code>container-network</code> option. You can specify <code>container-network-dns</code> multiple times, to configure multiple DNS servers. If you specify <code>container-network-dns</code> but you do not specify <code>container-network</code>, or if you specify a different distributed port group to the one that you specify in <code>container-network</code>, <code>vic-machine create</code> fails with an error.</p>
<pre>--container-network-dns <i>distributed_port_group_name</i>:8.8.8.8</pre>

<p>Wrap the distributed port group name in single quotes (Linux or Mac OS) or double quotes (Windows) if it includes spaces.</p>
<pre>--container-network-dns &apos;<i>distributed port group name</i>&apos;:8.8.8.8</pre>

<h3 id="containernetworkiprange"><code>--container-network-ip-range</code></h3>
<p>Short name: <code>--cnr</code></p>
<p>The range of IP addresses that container VMs can use if the network that you specify in the <code>container-network</code> option does not support DHCP. If you specify <code>--container-network-ip-range</code>, virtual container hosts manage the addresses for containers within that range. The range that you specify must not be used by other computers or VMs on the network. If you specify <code>container-network-gateway</code> but do not specify <code>--container-network-ip-range</code>, the IP range for container VMs is the entire subnet that you specify in <code>container-network-gateway</code>. </p>
<p>When you specify the container network IP range, you must use the distributed port group that you specify in the <code>container-network</code>option. If you specify <code>container-network-ip-range</code> but you do not specify <code>container-network</code>, or if you specify a different distributed port group to the one that you specify in <code>container-network</code>, <code>vic-machine create</code> fails with an error.</p>
<pre>--container-network-ip-range <i>distributed_port_group_name</i>:192.168.100.2-192.168.100.254</pre>

<p>You can also specify the IP range as a CIDR.</p>
<pre>--container-network-ip-range <i>distributed_port_group_name</i>:192.168.100.0/24</pre>

<p>Wrap the distributed port group name in single quotes (Linux or Mac OS) or double quotes (Windows) if it includes spaces.</p>
<pre>--container-network-ip-range &apos;<i>distributed port group name</i>&apos;:192.168.100.0/24</pre>

<p><a name="proxy"></a></p>
<h2 id="options-to-configure-virtual-container-hosts-to-use-proxy-servers">Options to Configure Virtual Container Hosts to Use Proxy Servers</h2>
<p>If your network access is controlled by a proxy server, you must   configure a virtual container host to connect to the proxy server when you deploy it.</p>
<p><strong>IMPORTANT</strong>: Configuring a virtual container host to use a proxy server does not configure proxy support on the containers that this virtual container host runs. Container developers must configure proxy servers on containers when they create them. </p>
<h3 id="httpproxy"><code>--http-proxy</code></h3>
<p>Short name: <code>--hproxy</code></p>
<p>The address of the HTTP proxy server through which the virtual container host accesses the network. Specify the address of the proxy server as either an FQDN or an IP address.</p>
<pre>--http-proxy http://<i>proxy_server_address</i>:<i>port</i></pre>

<h3 id="httpsproxy"><code>--https-proxy</code></h3>
<p>Short name: <code>--sproxy</code></p>
<p>The address of the HTTPS proxy server through which the virtual container host accesses the network. Specify the address of the proxy server as either an FQDN or an IP address.</p>
<pre>--https-proxy https://<i>proxy_server_address</i>:<i>port</i></pre>

<p><a name="adv-mgmt"></a></p>
<h2 id="advanced-resource-management-options">Advanced Resource Management Options</h2>
<h3 id="memoryreservation"><code>--memory-reservation</code></h3>
<p>Short name: <code>--memr</code></p>
<p>Reserve a quantity of memory for use by the virtual container host appliance and container VMs. Specify the memory reservation value in MB. If not specified, <code>vic-machine create</code> sets the reservation to 1.</p>
<pre>--memory-reservation 1024</pre>

<h3 id="memoryshares"><code>--memory-shares</code></h3>
<p>Short name: <code>--mems</code></p>
<p>Set memory shares on the virtual container host appliance. Specify the share value as a level or a number, for example <code>high</code>, <code>normal</code>, <code>low</code>, or <code>163840</code>. If not specified, <code>vic-machine create</code> sets the share to <code>normal</code>.</p>
<pre>--memory-shares low</pre>

<h3 id="cpureservation"><code>--cpu-reservation</code></h3>
<p>Short name: <code>--cpur</code></p>
<p>Reserve a quantity of CPU capacity for use by the virtual container host appliance and container VMs.  Specify the CPU reservation value in MHz. If not specified, <code>vic-machine create</code> sets the reservation to 1.</p>
<pre>--cpu-reservation 1024</pre>

<h3 id="cpushares"><code>--cpu-shares</code></h3>
<p>Short name: <code>--cpus</code></p>
<p>Set CPU shares on the virtual container host appliance. Specify the share value as a level or a number, for example <code>high</code>, <code>normal</code>, <code>low</code>, or <code>163840</code>. If not specified, <code>vic-machine create</code> sets the share to <code>normal</code>.</p>
<pre>--cpu-shares low</pre>

<h3 id="appliancecpu"><code>--appliance-cpu</code></h3>
<p>Short name: none</p>
<p>The number of virtual CPUs for the virtual container host endpoint VM. The default is 1. Set this option to increase the number of CPUs in the virtual container host VM, for example if the virtual container host will handle large volumes of containers, or containers that require a lot of processing power.</p>
<p><strong>NOTE</strong> Use the <code>--cpu</code> option instead of the <code>--appliance-cpu</code> option. The <code>--appliance-cpu</code> option is mainly intended for use by VMware Support.</p>
<pre>--appliance-cpu <i>number_of_CPUs</i></pre>

<h3 id="appliancememory"><code>--appliance-memory</code></h3>
<p>Short name: none</p>
<p>The amount of memory for the virtual container host endpoint VM. The default is 2048MB. Set this option to increase the amount of memory in the virtual container host VM, for example if the virtual container host will handle large volumes of containers, or containers that consume a lot of memory.</p>
<p><strong>NOTE</strong> Use the <code>--memory</code> option instead of the <code>--appliance-memory</code> option. The <code>--appliance-memory</code> option is mainly intended for use by VMware Support.</p>
<pre>--appliance-memory <i>amount_of_memory</i></pre>

<p><a name="adv-other"></a></p>
<h2 id="other-advanced-options">Other Advanced Options</h2>
<p><a name="bridge-range"></a></p>
<h3 id="bridgenetworkrange"><code>--bridge-network-range</code></h3>
<p>Short name: <code>--bnr</code></p>
<p>The range of IP addresses that additional bridge networks can use when container application developers use <code>docker network create</code> to create new bridge networks. If you do not specify the <code>bridge-network-range</code> option, the IP range for bridge networks is 172.16.0.0/12.</p>
<p>When you specify the bridge network IP range, you specify the IP range as a CIDR.</p>
<pre>--bridge-network-range 192.168.100.0/24</pre>


<h3 id="baseimagesize"><code>--base-image-size</code></h3>
<p>Short name: None</p>
<p>The size of the base image from which to create other images. You should not normally need to use this option. Specify the size in <code>GB</code> or <code>MB</code>. The default is 8GB. </p>
<pre>--base-image-size 4GB</pre>

<h3 id="containerstore"><code>--container-store</code></h3>
<p>Short name: <code>--cs</code></p>
<p>The <code>container-store</code> option is not enabled. Container VM files are stored in the datastore that you designate as the image store. </p>
<h3 id="applianceiso"><code>--appliance-iso</code></h3>
<p>Short name: <code>--ai</code></p>
<p>The path to the ISO image from which the virtual container host appliance boots. Set this option if you have moved the <code>appliance.iso</code> file to a folder that is not the folder that contains the <code>vic-machine</code> binary or is not the folder from which you are running <code>vic-machine</code>. Include the name of the ISO file in the path.</p>
<p><strong>NOTE</strong>: Do not use the <code>--appliance-iso</code> option to point <code>vic-machine</code> to an <code>--appliance-iso</code> file that is of a different version to the version of <code>vic-machine</code> that you are running.</p>
<pre>--appliance-iso <i>path_to_ISO_file</i>/appliance.iso</pre>

<p>Wrap the folder names in the path in single quotes (Linux or Mac OS) or double quotes (Windows) if they include spaces.</p>
<pre>--appliance-iso &apos;<i>path to ISO file</i>&apos;/appliance.iso</pre>

<h3 id="bootstrapiso"><code>--bootstrap-iso</code></h3>
<p>Short name: <code>--bi</code></p>
<p>The path to the ISO image from which to boot container VMs. Set this option if you have moved the <code>bootstrap.iso</code> file to a folder that is not the folder that contains the <code>vic-machine</code> binary or is not the folder from which you are running <code>vic-machine</code>. Include the name of the ISO file in the path.</p>
<p><strong>NOTE</strong>: Do not use the <code>--bootstrap-iso</code> option to point <code>vic-machine</code> to a <code>--bootstrap-iso</code> file that is of a different version to the version of <code>vic-machine</code> that you are running.</p>
<pre>--bootstrap-iso <i>path_to_ISO_file</i>/bootstrap.iso</pre>

<p>Wrap the folder names in the path in single quotes (Linux or Mac OS) or double quotes (Windows) if they include spaces.</p>
<pre>--bootstrap-iso &apos;<i>path to ISO file</i>&apos;/bootstrap.iso</pre>

<h3 id="userp"><code>--use-rp</code></h3>
<p>Short name: none</p>
<p>Deploy the virtual container host appliance to a resource pool on vCenter Server rather than to a vApp. If you specify this option, <code>vic-machine create</code> creates a resource pool with the same name as the virtual container host.</p>
<pre>--use-rp</pre>


<h3 id="debug"><code>--debug</code></h3>
<p>Short name: <code>-v</code></p>
<p>Provide verbose logging output, for troubleshooting purposes when running <code>vic-machine create</code>. If not specified, the <code>debug</code> value is set to 0 and verbose logging is disabled. Provide a value of 1 or greater to increase the verbosity of the logging. Note that setting debug to a value greater than 1 can affect the behavior of <code>vic-machine create</code>.</p>
<pre>--debug 1</pre>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="./install_vic_cli.html" class="navigation navigation-prev " aria-label="Previous page: Deploy a Virtual Container Host"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="./vch_installer_examples.html" class="navigation navigation-next " aria-label="Next page: Examples of Deploying a Virtual Container Host"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="gitbook/app.js"></script>

    
    <script src="gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
